{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malaria Life-Cycle Stage Classification with DenseNet\n",
    "This notebook builds a high-accuracy image classification pipeline using **DenseNet121** to recognize malaria life-cycle stages in thin blood smear images.\n",
    "The dataset originates from [A Dataset and Benchmark for Malaria Life Cycle Classification](https://github.com/QaziAmmar/A-Dataset-and-Benchmark-for-Malaria-Life-Cycle-Classification-in-Thin-Blood-Smear-Images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random, itertools\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to dataset images and annotation file\n",
    "DATA_DIR = '../IML_Malaria'\n",
    "ANN_FILE = '../annotations.json'\n",
    "\n",
    "with open(ANN_FILE) as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# Flatten annotations into a list of records with bbox and label\n",
    "dataset_records = []\n",
    "for entry in annotations:\n",
    "    img_name = entry['image_name']\n",
    "    for obj in entry['objects']:\n",
    "        label = obj['type']\n",
    "        bbox = [int(obj['bbox']['x']), int(obj['bbox']['y']),\n",
    "                int(obj['bbox']['w']), int(obj['bbox']['h'])]\n",
    "        dataset_records.append({'image': img_name, 'label': label, 'bbox': bbox})\n",
    "\n",
    "labels = [rec['label'] for rec in dataset_records]\n",
    "print('Total objects:', len(labels))\n",
    "print(Counter(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize random samples with bounding boxes\n",
    "samples = random.sample(dataset_records, 4)\n",
    "fig, axes = plt.subplots(1, len(samples), figsize=(15, 5))\n",
    "for ax, rec in zip(axes, samples):\n",
    "    img = Image.open(os.path.join(DATA_DIR, rec['image'])).convert('RGB')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    x, y, w, h = rec['bbox']\n",
    "    draw.rectangle([x, y, x+w, y+h], outline='red', width=2)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(rec['label'])\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map string labels to indices\n",
    "classes = sorted(set(labels))\n",
    "label2idx = {c: i for i, c in enumerate(classes)}\n",
    "idx2label = {i: c for c, i in label2idx.items()}\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalariaDataset(Dataset):\n",
    "    def __init__(self, records, transform=None):\n",
    "        self.records = records\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rec = self.records[idx]\n",
    "        img = Image.open(os.path.join(DATA_DIR, rec['image'])).convert('RGB')\n",
    "        x, y, w, h = rec['bbox']\n",
    "        img = img.crop((x, y, x+w, y+h))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = label2idx[rec['label']]\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split the records\n",
    "def split_dataset(records, train_ratio=0.7, val_ratio=0.15):\n",
    "    random.shuffle(records)\n",
    "    n = len(records)\n",
    "    train_end = int(n * train_ratio)\n",
    "    val_end = int(n * (train_ratio + val_ratio))\n",
    "    return records[:train_end], records[train_end:val_end], records[val_end:]\n",
    "\n",
    "train_records, val_records, test_records = split_dataset(dataset_records)\n",
    "\n",
    "print(len(train_records), len(val_records), len(test_records))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights for WeightedRandomSampler\n",
    "train_labels = [r['label'] for r in train_records]\n",
    "label_counts = Counter(train_labels)\n",
    "weights = [1.0 / label_counts[r['label']] for r in train_records]\n",
    "train_sampler = WeightedRandomSampler(weights, num_samples=len(train_records), replacement=True)\n",
    "\n",
    "train_ds = MalariaDataset(train_records, transform=train_transforms)\n",
    "val_ds = MalariaDataset(val_records, transform=val_transforms)\n",
    "test_ds = MalariaDataset(test_records, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, sampler=train_sampler)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "num_features = model.classifier.in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(num_features, len(classes))\n",
    ")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "def train_epoch(loader):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for images, labels in tqdm(loader, leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "def eval_epoch(loader):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return running_loss / total, correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_epoch(train_loader)\n",
    "    val_loss, val_acc = eval_epoch(val_loader)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - '\n",
    "          f'Train loss: {train_loss:.4f} acc: {train_acc:.4f} | '\n",
    "          f'Val loss: {val_loss:.4f} acc: {val_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.plot(history['train_loss'], label='train')\n",
    "ax1.plot(history['val_loss'], label='val')\n",
    "ax1.set_title('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history['train_acc'], label='train')\n",
    "ax2.plot(history['val_acc'], label='val')\n",
    "ax2.set_title('Accuracy')\n",
    "ax2.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = outputs.max(1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "prec = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "rec = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "print(f'Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}')\n",
    "print(classification_report(all_labels, all_preds, target_names=classes))\n",
    "cm = confusion_matrix(all_labels, all_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-CAM visualization for interpretability\n",
    "# Install grad-cam library if not available\n",
    "try:\n",
    "    from pytorch_grad_cam import GradCAM\n",
    "    from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "except ImportError:\n",
    "    print('Install pytorch-grad-cam to use Grad-CAM')\n",
    "\n",
    "# Choose a test image\n",
    "sample_img, sample_label = test_ds[0]\n",
    "input_tensor = sample_img.unsqueeze(0).to(device)\n",
    "\n",
    "# Target layer for DenseNet121\n",
    "target_layers = [model.features[-1]]\n",
    "cam = GradCAM(model=model, target_layers=target_layers, use_cuda=device.type=='cuda')\n",
    "mask = cam(input_tensor)[0]\n",
    "img = sample_img.permute(1,2,0).numpy()\n",
    "heatmap = show_cam_on_image(img, mask, use_rgb=True)\n",
    "plt.imshow(heatmap)\n",
    "plt.title(f'True: {idx2label[sample_label]}')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'densenet_malaria.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
